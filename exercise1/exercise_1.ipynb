{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 1\n",
    "\n",
    "\n",
    "\n",
    "### Read the Dataset\n",
    "\n",
    "- Use Pandas to read the 'covertype.csv' file\n",
    "- The dataset contains information on different forest cover types\n",
    "- Look at the columns. Which of them contain meaningful features?\n",
    "\n",
    "\n",
    "\n",
    "### Seperate Features and Labels\n",
    "- Define x as the vectors of meaningful features\n",
    "- Define y as the labels (Cover_Type)\n",
    "\n",
    "\n",
    "\n",
    "### Split the dataset into two disjoint datasets for training and testing\n",
    "- Randomly split the dataset. Use 70% for training and 30% for testing.\n",
    "- Define x_train and x_test as the feature vectors\n",
    "- Define y_train and y_test as the labels\n",
    "    - Hint: Have a look at the sklearn package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a simple deep neural network\n",
    "- Use Pytorch to define a simple Multi-Layer Perceptron with at least 3 layers\n",
    "    - The input layer should have as many neurons as there are features\n",
    "        - How many features are there?\n",
    "    - The last layer should have as many neurons as there are classes\n",
    "        - How many classes are there?\n",
    "- Pack your training and testing datasets in a class which inherits from torch.utils.data.Datset\n",
    "    - features you input to your network should be of type torch.float\n",
    "    - labels should be of type torch.long.\n",
    "- Use a torch.utils.data.DataLoader to access your data in batches\n",
    "- Train the MLP with your data from the train_loader using Cross-Entropy Loss and the Adam Optimizer\n",
    "    - Make sure to save the training history for later assessment\n",
    "- Evaluate the performance on your test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define your MLP\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your DataLoaders\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the network, the optimizer and the Loss Criterion\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your training Loop\n",
    "def train_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0.\n",
    "    samples = 0.\n",
    "    for sample in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        data, label = sample\n",
    "        prediction = model(data)\n",
    "        loss = criterion(prediction, label)\n",
    "        correct += sum(torch.argmax(prediction, dim=1) == label)\n",
    "        samples += len(data)\n",
    "        epoch_loss += loss.data\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return epoch_loss, correct/samples\n",
    "\n",
    "\n",
    "# Define your testing Loop\n",
    "def test_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    correct = 0.\n",
    "    samples = 0.\n",
    "    for sample in dataloader:\n",
    "        data, label = sample\n",
    "        prediction = model(data)\n",
    "        loss = criterion(prediction, label)\n",
    "        correct += sum(torch.argmax(prediction, dim=1) == label)\n",
    "        samples += len(data)\n",
    "        epoch_loss += loss.data\n",
    "    return epoch_loss, correct/samples\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if your training and testing loops are working\n",
    "train_epoch(net, train_loader, criterion, optimizer)\n",
    "test_epoch(net, train_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug\n",
    "- If there is a RuntimeError raised in you loss function, either your network architecture or your data is faulty\n",
    "    - Check your network architecture\n",
    "    - Check your data\n",
    "        - Are there any NaN or infinite features or labels?\n",
    "    - Print the labels.\n",
    "        - How many unique labels do you have?\n",
    "        - Are they [0, ..., n-1]?\n",
    "            - If not, align them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect your data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix your data and recreate your DataLoaders\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your Network\n",
    "- Reinitialize your MLP from above and train it for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "# net = \n",
    "# optimizer = \n",
    "\n",
    "train_loss, train_accuracy = [], []\n",
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "for i in tqdm.tnrange(100):\n",
    "    loss, accuracy = train_epoch(net, train_loader, criterion, optimizer)\n",
    "    train_loss.append(loss)\n",
    "    train_accuracy.append(accuracy)\n",
    "    loss, accuracy = test_epoch(net, train_loader, criterion)\n",
    "    test_loss.append(loss)\n",
    "    test_accuracy.append(accuracy)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it work?\n",
    "- There should not be a RuntimeError raised now\n",
    "- Does the network converge / Does the loss decrease?\n",
    "\n",
    "\n",
    "### Visualize the training\n",
    "- use matplotlib.pyplot to visualize the history\n",
    "- plot both the training accuracy and the validation accuracy\n",
    "- Does the training stagnate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data\n",
    "- Compute the min, max, mean and standard deviation of each feature\n",
    "- What data type do the columns have?\n",
    "- Use Pandas to print the statistics in a table\n",
    "- What could be problematic with the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "stats = pd.DataFrame(columns=[\"Type\", \"Min\", \"Max\", \"Mean\", \"Std\"])\n",
    "\n",
    "# Compute the values for each column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the Data\n",
    "- Normalize or standardize your data, so all features are at the same scale.\n",
    "    - This will help your network to use all available features and not be biased by some features with large values\n",
    "    - Does it make sense to normalize all columns, or only some?\n",
    "- Hint: Again, look if you find something useful in sklearn\n",
    "\n",
    "\n",
    "- Never use test data to optimize your training! This includes the preprocessing\n",
    "    - Find preprocessing parameters on your training data only!\n",
    "    - Transform all your data with the computed parameters\n",
    "    - You have to remember which of your samples are used for training and which are for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect data again\n",
    "- Print the statistics of the preprocessed data using the code from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(columns=[\"Type\", \"Min\", \"Max\", \"Mean\", \"Std\"])\n",
    "\n",
    "# Compute the values for each column\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network again\n",
    "- Recreate your DataLoaders with the normalized data\n",
    "- Reinitialize or your MLP from above and train it again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate your DataLoaders with the normalized data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = \n",
    "# optimizer = \n",
    "\n",
    "train_loss, train_accuracy = [], []\n",
    "test_loss, test_accuracy = [], []\n",
    "\n",
    "for i in tqdm.tnrange(100):\n",
    "    loss, accuracy = train_epoch(net, train_loader, criterion, optimizer)\n",
    "    train_loss.append(loss)\n",
    "    train_accuracy.append(accuracy)\n",
    "    loss, accuracy = test_epoch(net, train_loader, criterion)\n",
    "    test_loss.append(loss)\n",
    "    test_accuracy.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training\n",
    "- use matplotlib.pyplot to visualize the history\n",
    "- plot both the training accuracy and the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
