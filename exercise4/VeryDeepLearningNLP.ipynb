{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (NLP): Very Deep Learning\n",
    "\n",
    "**Natural language processing (NLP)** is the ability of a computer program to understand human language as it is spoken. It involves a pipeline of steps and by the end of the exercise, we would be able to classify the sentiment of a given review as POSITIVE or NEGATIVE.\n",
    "\n",
    "\n",
    "Before starting, it is important to understand the need for RNNs and the lecture from Stanford is a must to see before starting the exercise:\n",
    "\n",
    "https://www.youtube.com/watch?v=iX5V1WpxxkY\n",
    "\n",
    "When done, let's begin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this exercise, we will import libraries when needed so that we understand the need for it. \n",
    "# However, this is a bad practice and don't get used to it.\n",
    "import numpy as np\n",
    "\n",
    "# read data from reviews and labels file.\n",
    "with open('data/reviews.txt', 'r') as f:\n",
    "    reviews_ = f.readlines()\n",
    "with open('data/labels.txt', 'r') as f:\n",
    "    \n",
    "    labels = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "\t: bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life...\n",
      "negative\n",
      "\t: story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terr...\n",
      "positive\n",
      "\t: homelessness  or houselessness as george carlin stated  has been an issue for years but never a plan...\n",
      "negative\n",
      "\t: airport    starts as a brand new luxury    plane is loaded up with valuable paintings  such belongin...\n",
      "positive\n",
      "\t: brilliant over  acting by lesley ann warren . best dramatic hobo lady i have ever seen  and love sce...\n"
     ]
    }
   ],
   "source": [
    "# One of the most important task is to visualize data before starting with any ML task. \n",
    "for i in range(5):\n",
    "    print(labels[i] + \"\\t: \" + reviews_[i][:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can see there are a lot of punctuation marks like fullstop(.), comma(,), new line (\\n) and so on and we need to remove it. \n",
    "\n",
    "Here is a list of all the punctuation marks that needs to be removed \n",
    "```\n",
    "(!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Remove all the punctuation marks from the reviews.\n",
    "Many ways of doing it: Regex, Spacy, import punctuation from string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make everything lower case to make the whole dataset even. \n",
    "reviews = ''.join(reviews_).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# complete the function below to remove punctuations and save it in no_punct_text\n",
    "\n",
    "def text_without_punct(reviews):\n",
    "    pass\n",
    "\n",
    "no_punct_text = text_without_punct(reviews)\n",
    "reviews_split = no_punct_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the formatted no_punct_text into words\n",
    "def split_in_words(no_punct_text):\n",
    "    pass\n",
    "\n",
    "words = split_in_words(no_punct_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once you are done print the ten words that should yield the following output\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6020196"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the total length of the words\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74072"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of unique words\n",
    "len(set(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next step is to create a vocabulary. This way every word is mapped to an integer number.\n",
    "```\n",
    "Example: 1: hello, 2: I, 3: am, 4: Robo and so on...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1658\n"
     ]
    }
   ],
   "source": [
    "# Lets create a vocab out of it\n",
    "\n",
    "# feel free to use this import \n",
    "from collections import Counter\n",
    "\n",
    "## Let's keep a count of all the words and let's see how many words are there. \n",
    "def word_count(words):\n",
    "    return Counter(words)\n",
    "\n",
    "counts=word_count(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1658\n",
      "9308\n"
     ]
    }
   ],
   "source": [
    "# If you did everything correct, this is what you should get as output. \n",
    "print (counts['wonderful'])\n",
    "\n",
    "print (counts['bad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Word to Integer and Integer to word\n",
    "The task is to map every word to an integer value and then vice-versa. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a vocabulary for the words\n",
    "def vocabulary(counts):\n",
    "    pass\n",
    "\n",
    "vocab = vocabulary(counts)\n",
    "print(len(vocab))\n",
    "vocab[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map each vocab word to an integer. Also, start the indexing with 1 as we will use \n",
    "# '0' for padding and we dont want to mix the two.\n",
    "def vocabulary_to_integer(vocab):\n",
    "    pass\n",
    "\n",
    "vocab_to_int = vocabulary_to_integer(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify if the length is same and if 'and' is mapped to the correct integer value.\n",
    "print(len(vocab_to_int))\n",
    "vocab_to_int['and']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what positve words in positive reviews we have and what we have in negative reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(reviews_)):\n",
    "    if(labels[i] == 'positive\\n'):\n",
    "        for word in reviews_[i].split(\" \"):\n",
    "            positive_counts[word] += 1\n",
    "    else:\n",
    "        for word in reviews_[i].split(\" \"):\n",
    "            negative_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " 'positive\\n',\n",
       " 'negative\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 537968),\n",
       " ('the', 173324),\n",
       " ('.', 159654),\n",
       " ('and', 89722),\n",
       " ('a', 83688),\n",
       " ('of', 76855),\n",
       " ('to', 66746),\n",
       " ('is', 57245),\n",
       " ('in', 50215),\n",
       " ('br', 49235),\n",
       " ('it', 48025),\n",
       " ('i', 40743),\n",
       " ('that', 35630),\n",
       " ('this', 35080),\n",
       " ('s', 33815),\n",
       " ('as', 26308),\n",
       " ('with', 23247),\n",
       " ('for', 22416),\n",
       " ('was', 21917),\n",
       " ('film', 20937),\n",
       " ('but', 20822),\n",
       " ('movie', 19074),\n",
       " ('his', 17227),\n",
       " ('on', 17008),\n",
       " ('you', 16681),\n",
       " ('he', 16282),\n",
       " ('are', 14807),\n",
       " ('not', 14272),\n",
       " ('t', 13720),\n",
       " ('one', 13655),\n",
       " ('have', 12587),\n",
       " ('\\n', 12500),\n",
       " ('be', 12416),\n",
       " ('by', 11997),\n",
       " ('all', 11942),\n",
       " ('who', 11464),\n",
       " ('an', 11294),\n",
       " ('at', 11234),\n",
       " ('from', 10767),\n",
       " ('her', 10474),\n",
       " ('they', 9895),\n",
       " ('has', 9186),\n",
       " ('so', 9154),\n",
       " ('like', 9038),\n",
       " ('about', 8313),\n",
       " ('very', 8305),\n",
       " ('out', 8134),\n",
       " ('there', 8057),\n",
       " ('she', 7779),\n",
       " ('what', 7737),\n",
       " ('or', 7732),\n",
       " ('good', 7720),\n",
       " ('more', 7521),\n",
       " ('when', 7456),\n",
       " ('some', 7441),\n",
       " ('if', 7285),\n",
       " ('just', 7152),\n",
       " ('can', 7001),\n",
       " ('story', 6780),\n",
       " ('time', 6515),\n",
       " ('my', 6488),\n",
       " ('great', 6419),\n",
       " ('well', 6405),\n",
       " ('up', 6321),\n",
       " ('which', 6267),\n",
       " ('their', 6107),\n",
       " ('see', 6026),\n",
       " ('also', 5550),\n",
       " ('we', 5531),\n",
       " ('really', 5476),\n",
       " ('would', 5400),\n",
       " ('will', 5218),\n",
       " ('me', 5167),\n",
       " ('had', 5148),\n",
       " ('only', 5137),\n",
       " ('him', 5018),\n",
       " ('even', 4964),\n",
       " ('most', 4864),\n",
       " ('other', 4858),\n",
       " ('were', 4782),\n",
       " ('first', 4755),\n",
       " ('than', 4736),\n",
       " ('much', 4685),\n",
       " ('its', 4622),\n",
       " ('no', 4574),\n",
       " ('into', 4544),\n",
       " ('people', 4479),\n",
       " ('best', 4319),\n",
       " ('love', 4301),\n",
       " ('get', 4272),\n",
       " ('how', 4213),\n",
       " ('life', 4199),\n",
       " ('been', 4189),\n",
       " ('because', 4079),\n",
       " ('way', 4036),\n",
       " ('do', 3941),\n",
       " ('made', 3823),\n",
       " ('films', 3813),\n",
       " ('them', 3805),\n",
       " ('after', 3800),\n",
       " ('many', 3766),\n",
       " ('two', 3733),\n",
       " ('too', 3659),\n",
       " ('think', 3655),\n",
       " ('movies', 3586),\n",
       " ('characters', 3560),\n",
       " ('character', 3514),\n",
       " ('don', 3468),\n",
       " ('man', 3460),\n",
       " ('show', 3432),\n",
       " ('watch', 3424),\n",
       " ('seen', 3414),\n",
       " ('then', 3358),\n",
       " ('little', 3341),\n",
       " ('still', 3340),\n",
       " ('make', 3303),\n",
       " ('could', 3237),\n",
       " ('never', 3226),\n",
       " ('being', 3217),\n",
       " ('where', 3173),\n",
       " ('does', 3069),\n",
       " ('over', 3017),\n",
       " ('any', 3002),\n",
       " ('while', 2899),\n",
       " ('know', 2833),\n",
       " ('did', 2790),\n",
       " ('years', 2758),\n",
       " ('here', 2740),\n",
       " ('ever', 2734),\n",
       " ('end', 2696),\n",
       " ('these', 2694),\n",
       " ('such', 2590),\n",
       " ('real', 2568),\n",
       " ('scene', 2567),\n",
       " ('back', 2547),\n",
       " ('those', 2485),\n",
       " ('though', 2475),\n",
       " ('off', 2463),\n",
       " ('new', 2458),\n",
       " ('your', 2453),\n",
       " ('go', 2440),\n",
       " ('acting', 2437),\n",
       " ('plot', 2432),\n",
       " ('world', 2429),\n",
       " ('scenes', 2427),\n",
       " ('say', 2414),\n",
       " ('through', 2409),\n",
       " ('makes', 2390),\n",
       " ('better', 2381),\n",
       " ('now', 2368),\n",
       " ('work', 2346),\n",
       " ('young', 2343),\n",
       " ('old', 2311),\n",
       " ('ve', 2307),\n",
       " ('find', 2272),\n",
       " ('both', 2248),\n",
       " ('before', 2177),\n",
       " ('us', 2162),\n",
       " ('again', 2158),\n",
       " ('series', 2153),\n",
       " ('quite', 2143),\n",
       " ('something', 2135),\n",
       " ('cast', 2133),\n",
       " ('should', 2121),\n",
       " ('part', 2098),\n",
       " ('always', 2088),\n",
       " ('lot', 2087),\n",
       " ('another', 2075),\n",
       " ('actors', 2047),\n",
       " ('director', 2040),\n",
       " ('family', 2032),\n",
       " ('between', 2016),\n",
       " ('own', 2016),\n",
       " ('m', 1998),\n",
       " ('may', 1997),\n",
       " ('same', 1972),\n",
       " ('role', 1967),\n",
       " ('watching', 1966),\n",
       " ('every', 1954),\n",
       " ('funny', 1953),\n",
       " ('doesn', 1935),\n",
       " ('performance', 1928),\n",
       " ('few', 1918),\n",
       " ('bad', 1907),\n",
       " ('look', 1900),\n",
       " ('re', 1884),\n",
       " ('why', 1855),\n",
       " ('things', 1849),\n",
       " ('times', 1832),\n",
       " ('big', 1815),\n",
       " ('however', 1795),\n",
       " ('actually', 1790),\n",
       " ('action', 1789),\n",
       " ('going', 1783),\n",
       " ('bit', 1757),\n",
       " ('comedy', 1742),\n",
       " ('down', 1740),\n",
       " ('music', 1738),\n",
       " ('must', 1728),\n",
       " ('take', 1709),\n",
       " ('saw', 1692),\n",
       " ('long', 1690),\n",
       " ('right', 1688),\n",
       " ('fun', 1686),\n",
       " ('fact', 1684),\n",
       " ('excellent', 1683),\n",
       " ('around', 1674),\n",
       " ('didn', 1672),\n",
       " ('without', 1671),\n",
       " ('thing', 1662),\n",
       " ('thought', 1639),\n",
       " ('got', 1635),\n",
       " ('each', 1630),\n",
       " ('day', 1614),\n",
       " ('feel', 1597),\n",
       " ('seems', 1596),\n",
       " ('come', 1594),\n",
       " ('done', 1586),\n",
       " ('beautiful', 1580),\n",
       " ('especially', 1572),\n",
       " ('played', 1571),\n",
       " ('almost', 1566),\n",
       " ('want', 1562),\n",
       " ('yet', 1556),\n",
       " ('give', 1553),\n",
       " ('pretty', 1549),\n",
       " ('last', 1543),\n",
       " ('since', 1519),\n",
       " ('different', 1504),\n",
       " ('although', 1501),\n",
       " ('gets', 1490),\n",
       " ('true', 1487),\n",
       " ('interesting', 1481),\n",
       " ('job', 1470),\n",
       " ('enough', 1455),\n",
       " ('our', 1454),\n",
       " ('shows', 1447),\n",
       " ('horror', 1441),\n",
       " ('woman', 1439),\n",
       " ('tv', 1400),\n",
       " ('probably', 1398),\n",
       " ('father', 1395),\n",
       " ('original', 1393),\n",
       " ('girl', 1390),\n",
       " ('point', 1379),\n",
       " ('plays', 1378),\n",
       " ('wonderful', 1372),\n",
       " ('far', 1358),\n",
       " ('course', 1358),\n",
       " ('john', 1350),\n",
       " ('rather', 1340),\n",
       " ('isn', 1328),\n",
       " ('ll', 1326),\n",
       " ('later', 1324),\n",
       " ('dvd', 1324),\n",
       " ('whole', 1310),\n",
       " ('war', 1310),\n",
       " ('d', 1307),\n",
       " ('found', 1306),\n",
       " ('away', 1306),\n",
       " ('screen', 1305),\n",
       " ('nothing', 1300),\n",
       " ('year', 1297),\n",
       " ('once', 1296),\n",
       " ('hard', 1294),\n",
       " ('together', 1280),\n",
       " ('set', 1277),\n",
       " ('am', 1277),\n",
       " ('having', 1266),\n",
       " ('making', 1265),\n",
       " ('place', 1263),\n",
       " ('might', 1260),\n",
       " ('comes', 1260),\n",
       " ('sure', 1253),\n",
       " ('american', 1248),\n",
       " ('play', 1245),\n",
       " ('kind', 1244),\n",
       " ('perfect', 1242),\n",
       " ('takes', 1242),\n",
       " ('performances', 1237),\n",
       " ('himself', 1230),\n",
       " ('worth', 1221),\n",
       " ('everyone', 1221),\n",
       " ('anyone', 1214),\n",
       " ('actor', 1203),\n",
       " ('three', 1201),\n",
       " ('wife', 1196),\n",
       " ('classic', 1192),\n",
       " ('goes', 1186),\n",
       " ('ending', 1178),\n",
       " ('version', 1168),\n",
       " ('star', 1149),\n",
       " ('enjoy', 1146),\n",
       " ('book', 1142),\n",
       " ('nice', 1132),\n",
       " ('everything', 1128),\n",
       " ('during', 1124),\n",
       " ('put', 1118),\n",
       " ('seeing', 1111),\n",
       " ('least', 1102),\n",
       " ('house', 1100),\n",
       " ('high', 1095),\n",
       " ('watched', 1094),\n",
       " ('loved', 1087),\n",
       " ('men', 1087),\n",
       " ('night', 1082),\n",
       " ('anything', 1075),\n",
       " ('believe', 1071),\n",
       " ('guy', 1071),\n",
       " ('top', 1063),\n",
       " ('amazing', 1058),\n",
       " ('hollywood', 1056),\n",
       " ('looking', 1053),\n",
       " ('main', 1044),\n",
       " ('definitely', 1043),\n",
       " ('gives', 1031),\n",
       " ('home', 1029),\n",
       " ('seem', 1028),\n",
       " ('episode', 1023),\n",
       " ('audience', 1020),\n",
       " ('sense', 1020),\n",
       " ('truly', 1017),\n",
       " ('special', 1011),\n",
       " ('second', 1009),\n",
       " ('short', 1009),\n",
       " ('fan', 1009),\n",
       " ('mind', 1005),\n",
       " ('human', 1001),\n",
       " ('recommend', 999),\n",
       " ('full', 996),\n",
       " ('black', 995),\n",
       " ('help', 991),\n",
       " ('along', 989),\n",
       " ('trying', 987),\n",
       " ('small', 986),\n",
       " ('death', 985),\n",
       " ('friends', 981),\n",
       " ('remember', 974),\n",
       " ('often', 970),\n",
       " ('said', 966),\n",
       " ('favorite', 962),\n",
       " ('heart', 959),\n",
       " ('early', 957),\n",
       " ('left', 956),\n",
       " ('until', 955),\n",
       " ('script', 954),\n",
       " ('let', 954),\n",
       " ('maybe', 937),\n",
       " ('today', 936),\n",
       " ('live', 934),\n",
       " ('less', 934),\n",
       " ('moments', 933),\n",
       " ('others', 929),\n",
       " ('brilliant', 926),\n",
       " ('shot', 925),\n",
       " ('liked', 923),\n",
       " ('become', 916),\n",
       " ('won', 915),\n",
       " ('used', 910),\n",
       " ('style', 907),\n",
       " ('mother', 895),\n",
       " ('lives', 894),\n",
       " ('came', 893),\n",
       " ('stars', 890),\n",
       " ('cinema', 889),\n",
       " ('looks', 885),\n",
       " ('perhaps', 884),\n",
       " ('read', 882),\n",
       " ('enjoyed', 879),\n",
       " ('boy', 875),\n",
       " ('drama', 873),\n",
       " ('highly', 871),\n",
       " ('given', 870),\n",
       " ('playing', 867),\n",
       " ('use', 864),\n",
       " ('next', 859),\n",
       " ('women', 858),\n",
       " ('fine', 857),\n",
       " ('effects', 856),\n",
       " ('kids', 854),\n",
       " ('entertaining', 853),\n",
       " ('need', 852),\n",
       " ('line', 850),\n",
       " ('works', 848),\n",
       " ('someone', 847),\n",
       " ('mr', 836),\n",
       " ('simply', 835),\n",
       " ('picture', 833),\n",
       " ('children', 833),\n",
       " ('face', 831),\n",
       " ('keep', 831),\n",
       " ('friend', 831),\n",
       " ('dark', 830),\n",
       " ('overall', 828),\n",
       " ('certainly', 828),\n",
       " ('minutes', 827),\n",
       " ('wasn', 824),\n",
       " ('history', 822),\n",
       " ('finally', 820),\n",
       " ('couple', 816),\n",
       " ('against', 815),\n",
       " ('son', 809),\n",
       " ('understand', 808),\n",
       " ('lost', 807),\n",
       " ('michael', 805),\n",
       " ('else', 801),\n",
       " ('throughout', 798),\n",
       " ('fans', 797),\n",
       " ('city', 792),\n",
       " ('reason', 789),\n",
       " ('written', 787),\n",
       " ('production', 787),\n",
       " ('several', 784),\n",
       " ('school', 783),\n",
       " ('based', 781),\n",
       " ('rest', 781),\n",
       " ('try', 780),\n",
       " ('dead', 776),\n",
       " ('hope', 775),\n",
       " ('strong', 768),\n",
       " ('white', 765),\n",
       " ('tell', 759),\n",
       " ('itself', 758),\n",
       " ('half', 753),\n",
       " ('person', 749),\n",
       " ('sometimes', 746),\n",
       " ('past', 744),\n",
       " ('start', 744),\n",
       " ('genre', 743),\n",
       " ('beginning', 739),\n",
       " ('final', 739),\n",
       " ('town', 738),\n",
       " ('art', 734),\n",
       " ('humor', 732),\n",
       " ('game', 732),\n",
       " ('yes', 731),\n",
       " ('idea', 731),\n",
       " ('late', 730),\n",
       " ('becomes', 729),\n",
       " ('despite', 729),\n",
       " ('able', 726),\n",
       " ('case', 726),\n",
       " ('money', 723),\n",
       " ('child', 721),\n",
       " ('completely', 721),\n",
       " ('side', 719),\n",
       " ('camera', 716),\n",
       " ('getting', 714),\n",
       " ('instead', 712),\n",
       " ('soon', 702),\n",
       " ('under', 700),\n",
       " ('viewer', 699),\n",
       " ('age', 697),\n",
       " ('days', 696),\n",
       " ('stories', 696),\n",
       " ('felt', 694),\n",
       " ('simple', 694),\n",
       " ('roles', 693),\n",
       " ('video', 688),\n",
       " ('name', 683),\n",
       " ('either', 683),\n",
       " ('doing', 677),\n",
       " ('turns', 674),\n",
       " ('wants', 671),\n",
       " ('close', 671),\n",
       " ('title', 669),\n",
       " ('wrong', 668),\n",
       " ('went', 666),\n",
       " ('james', 665),\n",
       " ('evil', 659),\n",
       " ('budget', 657),\n",
       " ('episodes', 657),\n",
       " ('relationship', 655),\n",
       " ('fantastic', 653),\n",
       " ('piece', 653),\n",
       " ('david', 651),\n",
       " ('turn', 648),\n",
       " ('murder', 646),\n",
       " ('parts', 645),\n",
       " ('brother', 644),\n",
       " ('absolutely', 643),\n",
       " ('head', 643),\n",
       " ('experience', 642),\n",
       " ('eyes', 641),\n",
       " ('sex', 638),\n",
       " ('direction', 637),\n",
       " ('called', 637),\n",
       " ('directed', 636),\n",
       " ('lines', 634),\n",
       " ('behind', 633),\n",
       " ('sort', 632),\n",
       " ('actress', 631),\n",
       " ('lead', 630),\n",
       " ('oscar', 628),\n",
       " ('including', 627),\n",
       " ('example', 627),\n",
       " ('known', 625),\n",
       " ('musical', 625),\n",
       " ('chance', 621),\n",
       " ('score', 620),\n",
       " ('already', 619),\n",
       " ('feeling', 619),\n",
       " ('hit', 619),\n",
       " ('voice', 615),\n",
       " ('moment', 612),\n",
       " ('living', 612),\n",
       " ('low', 610),\n",
       " ('supporting', 610),\n",
       " ('ago', 609),\n",
       " ('themselves', 608),\n",
       " ('reality', 605),\n",
       " ('hilarious', 605),\n",
       " ('jack', 604),\n",
       " ('told', 603),\n",
       " ('hand', 601),\n",
       " ('quality', 600),\n",
       " ('moving', 600),\n",
       " ('dialogue', 600),\n",
       " ('song', 599),\n",
       " ('happy', 599),\n",
       " ('matter', 598),\n",
       " ('paul', 598),\n",
       " ('light', 594),\n",
       " ('future', 593),\n",
       " ('entire', 592),\n",
       " ('finds', 591),\n",
       " ('gave', 589),\n",
       " ('laugh', 587),\n",
       " ('released', 586),\n",
       " ('expect', 584),\n",
       " ('fight', 581),\n",
       " ('particularly', 580),\n",
       " ('cinematography', 579),\n",
       " ('police', 579),\n",
       " ('whose', 578),\n",
       " ('type', 578),\n",
       " ('sound', 578),\n",
       " ('view', 573),\n",
       " ('enjoyable', 573),\n",
       " ('number', 572),\n",
       " ('romantic', 572),\n",
       " ('husband', 572),\n",
       " ('daughter', 572),\n",
       " ('documentary', 571),\n",
       " ('self', 570),\n",
       " ('superb', 569),\n",
       " ('modern', 569),\n",
       " ('took', 569),\n",
       " ('robert', 569),\n",
       " ('mean', 566),\n",
       " ('shown', 563),\n",
       " ('coming', 561),\n",
       " ('important', 560),\n",
       " ('king', 559),\n",
       " ('leave', 559),\n",
       " ('change', 558),\n",
       " ('somewhat', 555),\n",
       " ('wanted', 555),\n",
       " ('tells', 554),\n",
       " ('events', 552),\n",
       " ('run', 552),\n",
       " ('career', 552),\n",
       " ('country', 552),\n",
       " ('heard', 550),\n",
       " ('season', 550),\n",
       " ('greatest', 549),\n",
       " ('girls', 549),\n",
       " ('etc', 547),\n",
       " ('care', 546),\n",
       " ('starts', 545),\n",
       " ('english', 542),\n",
       " ('killer', 541),\n",
       " ('tale', 540),\n",
       " ('guys', 540),\n",
       " ('totally', 540),\n",
       " ('animation', 540),\n",
       " ('usual', 539),\n",
       " ('miss', 535),\n",
       " ('opinion', 535),\n",
       " ('easy', 531),\n",
       " ('violence', 531),\n",
       " ('songs', 530),\n",
       " ('british', 528),\n",
       " ('says', 526),\n",
       " ('realistic', 525),\n",
       " ('writing', 524),\n",
       " ('writer', 522),\n",
       " ('act', 522),\n",
       " ('comic', 521),\n",
       " ('thriller', 519),\n",
       " ('television', 517),\n",
       " ('power', 516),\n",
       " ('ones', 515),\n",
       " ('kid', 514),\n",
       " ('york', 513),\n",
       " ('novel', 513),\n",
       " ('alone', 512),\n",
       " ('problem', 512),\n",
       " ('attention', 509),\n",
       " ('involved', 508),\n",
       " ('kill', 507),\n",
       " ('extremely', 507),\n",
       " ('seemed', 506),\n",
       " ('hero', 505),\n",
       " ('french', 505),\n",
       " ('rock', 504),\n",
       " ('stuff', 501),\n",
       " ('wish', 499),\n",
       " ('begins', 498),\n",
       " ('taken', 497),\n",
       " ('sad', 497),\n",
       " ('ways', 496),\n",
       " ('richard', 495),\n",
       " ('knows', 494),\n",
       " ('atmosphere', 493),\n",
       " ('similar', 491),\n",
       " ('surprised', 491),\n",
       " ('taking', 491),\n",
       " ('car', 491),\n",
       " ('george', 490),\n",
       " ('perfectly', 490),\n",
       " ('across', 489),\n",
       " ('team', 489),\n",
       " ('eye', 489),\n",
       " ('sequence', 489),\n",
       " ('room', 488),\n",
       " ('due', 488),\n",
       " ('among', 488),\n",
       " ('serious', 488),\n",
       " ('powerful', 488),\n",
       " ('strange', 487),\n",
       " ('order', 487),\n",
       " ('cannot', 487),\n",
       " ('b', 487),\n",
       " ('beauty', 486),\n",
       " ('famous', 485),\n",
       " ('happened', 484),\n",
       " ('tries', 484),\n",
       " ('herself', 484),\n",
       " ('myself', 484),\n",
       " ('class', 483),\n",
       " ('four', 482),\n",
       " ('cool', 481),\n",
       " ('release', 479),\n",
       " ('anyway', 479),\n",
       " ('theme', 479),\n",
       " ('opening', 478),\n",
       " ('entertainment', 477),\n",
       " ('slow', 475),\n",
       " ('ends', 475),\n",
       " ('unique', 475),\n",
       " ('exactly', 475),\n",
       " ('easily', 474),\n",
       " ('level', 474),\n",
       " ('o', 474),\n",
       " ('red', 474),\n",
       " ('interest', 472),\n",
       " ('happen', 471),\n",
       " ('crime', 470),\n",
       " ('viewing', 468),\n",
       " ('sets', 467),\n",
       " ('memorable', 467),\n",
       " ('stop', 466),\n",
       " ('group', 466),\n",
       " ('problems', 463),\n",
       " ('dance', 463),\n",
       " ('working', 463),\n",
       " ('sister', 463),\n",
       " ('message', 463),\n",
       " ('knew', 462),\n",
       " ('mystery', 461),\n",
       " ('nature', 461),\n",
       " ('bring', 460),\n",
       " ('believable', 459),\n",
       " ('thinking', 459),\n",
       " ('brought', 459),\n",
       " ('mostly', 458),\n",
       " ('disney', 457),\n",
       " ('couldn', 457),\n",
       " ('society', 456),\n",
       " ('lady', 455),\n",
       " ('within', 455),\n",
       " ('blood', 454),\n",
       " ('parents', 453),\n",
       " ('upon', 453),\n",
       " ('viewers', 453),\n",
       " ('meets', 452),\n",
       " ('form', 452),\n",
       " ('peter', 452),\n",
       " ('tom', 452),\n",
       " ('usually', 452),\n",
       " ('soundtrack', 452),\n",
       " ('local', 450),\n",
       " ('certain', 448),\n",
       " ('follow', 448),\n",
       " ('whether', 447),\n",
       " ('possible', 446),\n",
       " ('emotional', 445),\n",
       " ('killed', 444),\n",
       " ('above', 444),\n",
       " ('de', 444),\n",
       " ('god', 443),\n",
       " ('middle', 443),\n",
       " ('needs', 442),\n",
       " ('happens', 442),\n",
       " ('flick', 442),\n",
       " ('masterpiece', 441),\n",
       " ('period', 440),\n",
       " ('major', 440),\n",
       " ('named', 439),\n",
       " ('haven', 439),\n",
       " ('particular', 438),\n",
       " ('th', 438),\n",
       " ('earth', 437),\n",
       " ('feature', 437),\n",
       " ('stand', 436),\n",
       " ('words', 435),\n",
       " ('typical', 435),\n",
       " ('elements', 433),\n",
       " ('obviously', 433),\n",
       " ('romance', 431),\n",
       " ('jane', 430),\n",
       " ('yourself', 427),\n",
       " ('showing', 427),\n",
       " ('brings', 426),\n",
       " ('fantasy', 426),\n",
       " ('guess', 423),\n",
       " ('america', 423),\n",
       " ('unfortunately', 422),\n",
       " ('huge', 422),\n",
       " ('indeed', 421),\n",
       " ('running', 421),\n",
       " ('talent', 420),\n",
       " ('stage', 419),\n",
       " ('started', 418),\n",
       " ('leads', 417),\n",
       " ('sweet', 417),\n",
       " ('japanese', 417),\n",
       " ('poor', 416),\n",
       " ('deal', 416),\n",
       " ('incredible', 413),\n",
       " ('personal', 413),\n",
       " ('fast', 412),\n",
       " ('became', 410),\n",
       " ('deep', 410),\n",
       " ('hours', 409),\n",
       " ('giving', 408),\n",
       " ('nearly', 408),\n",
       " ('dream', 408),\n",
       " ('clearly', 407),\n",
       " ('turned', 407),\n",
       " ('obvious', 406),\n",
       " ('near', 406),\n",
       " ('cut', 405),\n",
       " ('surprise', 405),\n",
       " ('era', 404),\n",
       " ('body', 404),\n",
       " ('hour', 403),\n",
       " ('female', 403),\n",
       " ('five', 403),\n",
       " ('note', 399),\n",
       " ('learn', 398),\n",
       " ('truth', 398),\n",
       " ('except', 397),\n",
       " ('feels', 397),\n",
       " ('match', 397),\n",
       " ('tony', 397),\n",
       " ('filmed', 394),\n",
       " ('clear', 394),\n",
       " ('complete', 394),\n",
       " ('street', 393),\n",
       " ('eventually', 393),\n",
       " ('keeps', 393),\n",
       " ('older', 393),\n",
       " ('lots', 393),\n",
       " ('buy', 392),\n",
       " ('william', 391),\n",
       " ('stewart', 391),\n",
       " ('fall', 390),\n",
       " ('joe', 390),\n",
       " ('meet', 390),\n",
       " ('unlike', 389),\n",
       " ('talking', 389),\n",
       " ('shots', 389),\n",
       " ('rating', 389),\n",
       " ('difficult', 389),\n",
       " ('dramatic', 388),\n",
       " ('means', 388),\n",
       " ('situation', 386),\n",
       " ('wonder', 386),\n",
       " ('present', 386),\n",
       " ('appears', 386),\n",
       " ('subject', 386),\n",
       " ('comments', 385),\n",
       " ('general', 383),\n",
       " ('sequences', 383),\n",
       " ('lee', 383),\n",
       " ('points', 382),\n",
       " ('earlier', 382),\n",
       " ('gone', 379),\n",
       " ('check', 379),\n",
       " ('suspense', 378),\n",
       " ('recommended', 378),\n",
       " ('ten', 378),\n",
       " ('third', 377),\n",
       " ('business', 377),\n",
       " ('talk', 375),\n",
       " ('leaves', 375),\n",
       " ('beyond', 375),\n",
       " ('portrayal', 374),\n",
       " ('beautifully', 373),\n",
       " ('single', 372),\n",
       " ('bill', 372),\n",
       " ('plenty', 371),\n",
       " ('word', 371),\n",
       " ('whom', 370),\n",
       " ('falls', 370),\n",
       " ('scary', 369),\n",
       " ('non', 369),\n",
       " ('figure', 369),\n",
       " ('battle', 369),\n",
       " ('using', 368),\n",
       " ('return', 368),\n",
       " ('doubt', 367),\n",
       " ('add', 367),\n",
       " ('hear', 366),\n",
       " ('solid', 366),\n",
       " ('success', 366),\n",
       " ('jokes', 365),\n",
       " ('oh', 365),\n",
       " ('touching', 365),\n",
       " ('political', 365),\n",
       " ('hell', 364),\n",
       " ('awesome', 364),\n",
       " ('boys', 364),\n",
       " ('sexual', 362),\n",
       " ('recently', 362),\n",
       " ('dog', 362),\n",
       " ('please', 361),\n",
       " ('wouldn', 361),\n",
       " ('straight', 361),\n",
       " ('features', 361),\n",
       " ('forget', 360),\n",
       " ('setting', 360),\n",
       " ('lack', 360),\n",
       " ('married', 359),\n",
       " ('mark', 359),\n",
       " ('social', 357),\n",
       " ('interested', 356),\n",
       " ('adventure', 356),\n",
       " ('actual', 355),\n",
       " ('terrific', 355),\n",
       " ('sees', 355),\n",
       " ('brothers', 355),\n",
       " ('move', 354),\n",
       " ('call', 354),\n",
       " ('various', 353),\n",
       " ('theater', 353),\n",
       " ('dr', 353),\n",
       " ('animated', 352),\n",
       " ('western', 351),\n",
       " ('baby', 350),\n",
       " ('space', 350),\n",
       " ('leading', 348),\n",
       " ('disappointed', 348),\n",
       " ('portrayed', 346),\n",
       " ('aren', 346),\n",
       " ('screenplay', 345),\n",
       " ('smith', 345),\n",
       " ('towards', 344),\n",
       " ('hate', 344),\n",
       " ('noir', 343),\n",
       " ('outstanding', 342),\n",
       " ('decent', 342),\n",
       " ('kelly', 342),\n",
       " ('directors', 341),\n",
       " ('journey', 341),\n",
       " ('none', 340),\n",
       " ('looked', 340),\n",
       " ('effective', 340),\n",
       " ('storyline', 339),\n",
       " ('caught', 339),\n",
       " ('sci', 339),\n",
       " ('fi', 339),\n",
       " ('cold', 339),\n",
       " ('mary', 339),\n",
       " ('rich', 338),\n",
       " ('charming', 338),\n",
       " ('popular', 337),\n",
       " ('rare', 337),\n",
       " ('manages', 337),\n",
       " ('harry', 337),\n",
       " ('spirit', 336),\n",
       " ('appreciate', 335),\n",
       " ('open', 335),\n",
       " ('moves', 334),\n",
       " ('basically', 334),\n",
       " ('acted', 334),\n",
       " ('inside', 333),\n",
       " ('boring', 333),\n",
       " ('century', 333),\n",
       " ('mention', 333),\n",
       " ('deserves', 333),\n",
       " ('subtle', 333),\n",
       " ('pace', 333),\n",
       " ('familiar', 332),\n",
       " ('background', 332),\n",
       " ('ben', 331),\n",
       " ('creepy', 330),\n",
       " ('supposed', 330),\n",
       " ('secret', 329),\n",
       " ('die', 328),\n",
       " ('jim', 328),\n",
       " ('question', 327),\n",
       " ('effect', 327),\n",
       " ('natural', 327),\n",
       " ('impressive', 326),\n",
       " ('rate', 326),\n",
       " ('language', 326),\n",
       " ('saying', 325),\n",
       " ('intelligent', 325),\n",
       " ('telling', 324),\n",
       " ('realize', 324),\n",
       " ('material', 324),\n",
       " ('scott', 324),\n",
       " ('singing', 323),\n",
       " ('dancing', 322),\n",
       " ('visual', 321),\n",
       " ('adult', 321),\n",
       " ('imagine', 321),\n",
       " ('kept', 320),\n",
       " ('office', 320),\n",
       " ('uses', 319),\n",
       " ('pure', 318),\n",
       " ('wait', 318),\n",
       " ('stunning', 318),\n",
       " ('review', 317),\n",
       " ('previous', 317),\n",
       " ('copy', 317),\n",
       " ('seriously', 317),\n",
       " ('reading', 316),\n",
       " ('create', 316),\n",
       " ('hot', 316),\n",
       " ('created', 316),\n",
       " ('magic', 316),\n",
       " ('somehow', 316),\n",
       " ('stay', 315),\n",
       " ('attempt', 315),\n",
       " ('escape', 315),\n",
       " ('crazy', 315),\n",
       " ('air', 315),\n",
       " ('frank', 315),\n",
       " ('hands', 314),\n",
       " ('filled', 313),\n",
       " ('expected', 312),\n",
       " ('average', 312),\n",
       " ('surprisingly', 312),\n",
       " ('complex', 311),\n",
       " ('quickly', 310),\n",
       " ('successful', 310),\n",
       " ('studio', 310),\n",
       " ('plus', 309),\n",
       " ('male', 309),\n",
       " ('co', 307),\n",
       " ('images', 306),\n",
       " ('casting', 306),\n",
       " ('following', 306),\n",
       " ('minute', 306),\n",
       " ('exciting', 306),\n",
       " ('members', 305),\n",
       " ('follows', 305),\n",
       " ('themes', 305),\n",
       " ('german', 305),\n",
       " ('reasons', 305),\n",
       " ('e', 305),\n",
       " ('touch', 304),\n",
       " ('edge', 304),\n",
       " ('free', 304),\n",
       " ('cute', 304),\n",
       " ('genius', 304),\n",
       " ('outside', 303),\n",
       " ('reviews', 302),\n",
       " ('admit', 302),\n",
       " ('ok', 302),\n",
       " ('younger', 302),\n",
       " ('fighting', 301),\n",
       " ('odd', 301),\n",
       " ('master', 301),\n",
       " ('recent', 300),\n",
       " ('thanks', 300),\n",
       " ('break', 300),\n",
       " ('comment', 300),\n",
       " ('apart', 299),\n",
       " ('emotions', 298),\n",
       " ('lovely', 298),\n",
       " ('begin', 298),\n",
       " ('doctor', 297),\n",
       " ('party', 297),\n",
       " ('italian', 297),\n",
       " ('la', 296),\n",
       " ...]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 1635892),\n",
       " ('the', 500102),\n",
       " ('.', 494730),\n",
       " ('a', 242330),\n",
       " ('and', 238492),\n",
       " ('of', 214873),\n",
       " ('to', 204694),\n",
       " ('is', 157411),\n",
       " ('br', 154509),\n",
       " ('it', 144679),\n",
       " ('in', 137721),\n",
       " ('i', 134503),\n",
       " ('this', 116920),\n",
       " ('that', 110860),\n",
       " ('s', 96907),\n",
       " ('was', 74499),\n",
       " ('movie', 69004),\n",
       " ('as', 67558),\n",
       " ('for', 66270),\n",
       " ('with', 65003),\n",
       " ('but', 64384),\n",
       " ('film', 59373),\n",
       " ('t', 54442),\n",
       " ('you', 51779),\n",
       " ('on', 51392),\n",
       " ('not', 46980),\n",
       " ('are', 44053),\n",
       " ('he', 43994),\n",
       " ('have', 42875),\n",
       " ('his', 41521),\n",
       " ('be', 41498),\n",
       " ('one', 39923),\n",
       " ('\\n', 37500),\n",
       " ('all', 36014),\n",
       " ('they', 35917),\n",
       " ('at', 35792),\n",
       " ('by', 33095),\n",
       " ('so', 32080),\n",
       " ('an', 31826),\n",
       " ('like', 31514),\n",
       " ('who', 31402),\n",
       " ('from', 30229),\n",
       " ('there', 29607),\n",
       " ('just', 28390),\n",
       " ('or', 28276),\n",
       " ('about', 26435),\n",
       " ('her', 26368),\n",
       " ('if', 26321),\n",
       " ('out', 26092),\n",
       " ('what', 24581),\n",
       " ('has', 24394),\n",
       " ('some', 24053),\n",
       " ('good', 22566),\n",
       " ('can', 22307),\n",
       " ('more', 20981),\n",
       " ('when', 20908),\n",
       " ('no', 20860),\n",
       " ('she', 20667),\n",
       " ('even', 20338),\n",
       " ('up', 20261),\n",
       " ('very', 19833),\n",
       " ('would', 19472),\n",
       " ('time', 18933),\n",
       " ('only', 18699),\n",
       " ('my', 18518),\n",
       " ('really', 18000),\n",
       " ('which', 17827),\n",
       " ('had', 17432),\n",
       " ('story', 17196),\n",
       " ('see', 16930),\n",
       " ('were', 16784),\n",
       " ('bad', 16709),\n",
       " ('their', 16663),\n",
       " ('me', 16379),\n",
       " ('we', 16187),\n",
       " ('than', 15102),\n",
       " ('well', 14913),\n",
       " ('much', 14841),\n",
       " ('do', 14413),\n",
       " ('been', 14389),\n",
       " ('get', 14346),\n",
       " ('don', 14140),\n",
       " ('people', 14091),\n",
       " ('because', 14011),\n",
       " ('into', 13678),\n",
       " ('how', 13589),\n",
       " ('other', 13468),\n",
       " ('first', 13367),\n",
       " ('will', 13204),\n",
       " ('made', 12905),\n",
       " ('then', 12880),\n",
       " ('also', 12766),\n",
       " ('make', 12747),\n",
       " ('him', 12734),\n",
       " ('most', 12702),\n",
       " ('could', 12609),\n",
       " ('any', 12318),\n",
       " ('them', 12135),\n",
       " ('way', 12014),\n",
       " ('too', 12007),\n",
       " ('its', 11932),\n",
       " ('movies', 11746),\n",
       " ('great', 11699),\n",
       " ('after', 11476),\n",
       " ('think', 10941),\n",
       " ('characters', 10760),\n",
       " ('plot', 10740),\n",
       " ('acting', 10549),\n",
       " ('character', 10526),\n",
       " ('watch', 10524),\n",
       " ('two', 10079),\n",
       " ('being', 10003),\n",
       " ('films', 9967),\n",
       " ('seen', 9944),\n",
       " ('did', 9802),\n",
       " ('never', 9744),\n",
       " ('over', 9649),\n",
       " ('where', 9611),\n",
       " ('off', 9597),\n",
       " ('many', 9584),\n",
       " ('little', 9533),\n",
       " ('know', 9501),\n",
       " ('ever', 9260),\n",
       " ('show', 9156),\n",
       " ('better', 9097),\n",
       " ('life', 9057),\n",
       " ('your', 8919),\n",
       " ('does', 8811),\n",
       " ('here', 8794),\n",
       " ('why', 8781),\n",
       " ('love', 8605),\n",
       " ('end', 8604),\n",
       " ('best', 8507),\n",
       " ('man', 8492),\n",
       " ('say', 8378),\n",
       " ('scene', 8199),\n",
       " ('these', 8142),\n",
       " ('something', 8019),\n",
       " ('m', 7998),\n",
       " ('scenes', 7997),\n",
       " ('ve', 7965),\n",
       " ('should', 7961),\n",
       " ('still', 7906),\n",
       " ('go', 7874),\n",
       " ('while', 7735),\n",
       " ('such', 7678),\n",
       " ('through', 7529),\n",
       " ('back', 7395),\n",
       " ('thing', 7394),\n",
       " ('nothing', 7280),\n",
       " ('watching', 7246),\n",
       " ('doesn', 7137),\n",
       " ('re', 7124),\n",
       " ('didn', 6964),\n",
       " ('actors', 6921),\n",
       " ('those', 6909),\n",
       " ('real', 6908),\n",
       " ('director', 6850),\n",
       " ('now', 6842),\n",
       " ('old', 6741),\n",
       " ('actually', 6688),\n",
       " ('though', 6657),\n",
       " ('funny', 6625),\n",
       " ('another', 6583),\n",
       " ('before', 6471),\n",
       " ('going', 6421),\n",
       " ('work', 6400),\n",
       " ('look', 6394),\n",
       " ('years', 6276),\n",
       " ('few', 6234),\n",
       " ('new', 6166),\n",
       " ('same', 6134),\n",
       " ('makes', 6018),\n",
       " ('every', 6004),\n",
       " ('find', 5992),\n",
       " ('part', 5982),\n",
       " ('lot', 5871),\n",
       " ('again', 5856),\n",
       " ('want', 5844),\n",
       " ('pretty', 5779),\n",
       " ('horror', 5741),\n",
       " ('down', 5716),\n",
       " ('seems', 5642),\n",
       " ('around', 5560),\n",
       " ('got', 5539),\n",
       " ('things', 5527),\n",
       " ('cast', 5521),\n",
       " ('enough', 5449),\n",
       " ('us', 5418),\n",
       " ('fact', 5362),\n",
       " ('original', 5359),\n",
       " ('quite', 5335),\n",
       " ('take', 5309),\n",
       " ('however', 5275),\n",
       " ('world', 5237),\n",
       " ('thought', 5235),\n",
       " ('long', 5212),\n",
       " ('worst', 5212),\n",
       " ('give', 5199),\n",
       " ('big', 5139),\n",
       " ('least', 5124),\n",
       " ('script', 5102),\n",
       " ('minutes', 5079),\n",
       " ('point', 5069),\n",
       " ('isn', 5026),\n",
       " ('guy', 4999),\n",
       " ('young', 4977),\n",
       " ('right', 4938),\n",
       " ('action', 4921),\n",
       " ('gets', 4918),\n",
       " ('without', 4861),\n",
       " ('d', 4847),\n",
       " ('whole', 4846),\n",
       " ('anything', 4823),\n",
       " ('come', 4784),\n",
       " ('interesting', 4777),\n",
       " ('may', 4777),\n",
       " ('must', 4772),\n",
       " ('between', 4764),\n",
       " ('comedy', 4750),\n",
       " ('almost', 4714),\n",
       " ('own', 4682),\n",
       " ('series', 4679),\n",
       " ('making', 4655),\n",
       " ('times', 4644),\n",
       " ('saw', 4642),\n",
       " ('done', 4606),\n",
       " ('far', 4596),\n",
       " ('might', 4576),\n",
       " ('both', 4564),\n",
       " ('ll', 4460),\n",
       " ('role', 4411),\n",
       " ('always', 4390),\n",
       " ('family', 4372),\n",
       " ('music', 4370),\n",
       " ('bit', 4353),\n",
       " ('am', 4337),\n",
       " ('last', 4323),\n",
       " ('kind', 4322),\n",
       " ('girl', 4316),\n",
       " ('feel', 4305),\n",
       " ('since', 4295),\n",
       " ('probably', 4286),\n",
       " ('away', 4244),\n",
       " ('tv', 4164),\n",
       " ('woman', 4151),\n",
       " ('rather', 4128),\n",
       " ('sure', 4119),\n",
       " ('anyone', 4050),\n",
       " ('hard', 4042),\n",
       " ('money', 3999),\n",
       " ('trying', 3959),\n",
       " ('yet', 3948),\n",
       " ('looks', 3941),\n",
       " ('believe', 3939),\n",
       " ('looking', 3913),\n",
       " ('day', 3878),\n",
       " ('performance', 3864),\n",
       " ('reason', 3857),\n",
       " ('found', 3840),\n",
       " ('someone', 3827),\n",
       " ('having', 3826),\n",
       " ('wasn', 3792),\n",
       " ('maybe', 3745),\n",
       " ('let', 3724),\n",
       " ('comes', 3708),\n",
       " ('fun', 3700),\n",
       " ('goes', 3698),\n",
       " ('book', 3698),\n",
       " ('screen', 3681),\n",
       " ('instead', 3668),\n",
       " ('course', 3654),\n",
       " ('put', 3644),\n",
       " ('sense', 3632),\n",
       " ('set', 3631),\n",
       " ('played', 3605),\n",
       " ('although', 3573),\n",
       " ('actor', 3573),\n",
       " ('our', 3566),\n",
       " ('place', 3559),\n",
       " ('effects', 3552),\n",
       " ('ending', 3536),\n",
       " ('each', 3530),\n",
       " ('everything', 3522),\n",
       " ('especially', 3498),\n",
       " ('main', 3484),\n",
       " ('half', 3435),\n",
       " ('said', 3426),\n",
       " ('year', 3425),\n",
       " ('three', 3389),\n",
       " ('watched', 3378),\n",
       " ('poor', 3378),\n",
       " ('audience', 3376),\n",
       " ('dvd', 3366),\n",
       " ('once', 3362),\n",
       " ('idea', 3355),\n",
       " ('worth', 3335),\n",
       " ('seem', 3322),\n",
       " ('left', 3294),\n",
       " ('boring', 3289),\n",
       " ('awful', 3282),\n",
       " ('house', 3270),\n",
       " ('different', 3260),\n",
       " ('night', 3248),\n",
       " ('play', 3231),\n",
       " ('high', 3227),\n",
       " ('everyone', 3225),\n",
       " ('special', 3215),\n",
       " ('american', 3208),\n",
       " ('together', 3206),\n",
       " ('else', 3199),\n",
       " ('true', 3179),\n",
       " ('shot', 3177),\n",
       " ('shows', 3167),\n",
       " ('version', 3146),\n",
       " ('takes', 3142),\n",
       " ('during', 3136),\n",
       " ('stupid', 3129),\n",
       " ('simply', 3095),\n",
       " ('himself', 3088),\n",
       " ('seeing', 3087),\n",
       " ('job', 3084),\n",
       " ('wife', 3084),\n",
       " ('later', 3074),\n",
       " ('black', 3073),\n",
       " ('less', 3068),\n",
       " ('john', 3066),\n",
       " ('completely', 3057),\n",
       " ('either', 3049),\n",
       " ('plays', 3048),\n",
       " ('read', 3046),\n",
       " ('terrible', 3029),\n",
       " ('star', 3017),\n",
       " ('budget', 3015),\n",
       " ('low', 2988),\n",
       " ('mind', 2985),\n",
       " ('dead', 2978),\n",
       " ('wrong', 2978),\n",
       " ('second', 2915),\n",
       " ('nice', 2892),\n",
       " ('line', 2886),\n",
       " ('try', 2882),\n",
       " ('used', 2848),\n",
       " ('father', 2847),\n",
       " ('camera', 2838),\n",
       " ('kids', 2832),\n",
       " ('death', 2829),\n",
       " ('given', 2826),\n",
       " ('rest', 2825),\n",
       " ('waste', 2815),\n",
       " ('fan', 2813),\n",
       " ('help', 2801),\n",
       " ('mean', 2800),\n",
       " ('production', 2793),\n",
       " ('war', 2792),\n",
       " ('video', 2774),\n",
       " ('women', 2774),\n",
       " ('beautiful', 2772),\n",
       " ('need', 2762),\n",
       " ('hollywood', 2756),\n",
       " ('use', 2744),\n",
       " ('men', 2731),\n",
       " ('sex', 2730),\n",
       " ('home', 2725),\n",
       " ('short', 2723),\n",
       " ('worse', 2718),\n",
       " ('supposed', 2702),\n",
       " ('tell', 2677),\n",
       " ('start', 2656),\n",
       " ('top', 2633),\n",
       " ('couple', 2620),\n",
       " ('friends', 2601),\n",
       " ('until', 2597),\n",
       " ('next', 2575),\n",
       " ('full', 2562),\n",
       " ('along', 2561),\n",
       " ('getting', 2540),\n",
       " ('school', 2535),\n",
       " ('oh', 2533),\n",
       " ('couldn', 2529),\n",
       " ('doing', 2529),\n",
       " ('name', 2525),\n",
       " ('stars', 2504),\n",
       " ('dialogue', 2484),\n",
       " ('perhaps', 2484),\n",
       " ('understand', 2480),\n",
       " ('enjoy', 2478),\n",
       " ('lines', 2472),\n",
       " ('truly', 2469),\n",
       " ('classic', 2466),\n",
       " ('face', 2459),\n",
       " ('excellent', 2459),\n",
       " ('came', 2453),\n",
       " ('written', 2445),\n",
       " ('won', 2443),\n",
       " ('person', 2441),\n",
       " ('head', 2439),\n",
       " ('remember', 2430),\n",
       " ('piece', 2421),\n",
       " ('performances', 2405),\n",
       " ('playing', 2399),\n",
       " ('moments', 2397),\n",
       " ('problem', 2388),\n",
       " ('keep', 2371),\n",
       " ('killer', 2369),\n",
       " ('itself', 2366),\n",
       " ('felt', 2362),\n",
       " ('case', 2340),\n",
       " ('recommend', 2337),\n",
       " ('yes', 2333),\n",
       " ('entire', 2330),\n",
       " ('absolutely', 2327),\n",
       " ('title', 2325),\n",
       " ('sort', 2312),\n",
       " ('small', 2306),\n",
       " ('lost', 2297),\n",
       " ('style', 2295),\n",
       " ('episode', 2293),\n",
       " ('unfortunately', 2284),\n",
       " ('others', 2261),\n",
       " ('went', 2260),\n",
       " ('early', 2253),\n",
       " ('finally', 2252),\n",
       " ('horrible', 2247),\n",
       " ('boy', 2245),\n",
       " ('evil', 2233),\n",
       " ('often', 2232),\n",
       " ('called', 2229),\n",
       " ('care', 2224),\n",
       " ('seemed', 2220),\n",
       " ('white', 2217),\n",
       " ('guess', 2199),\n",
       " ('human', 2191),\n",
       " ('children', 2185),\n",
       " ('live', 2170),\n",
       " ('become', 2170),\n",
       " ('laugh', 2163),\n",
       " ('mother', 2151),\n",
       " ('wanted', 2149),\n",
       " ('already', 2143),\n",
       " ('against', 2139),\n",
       " ('picture', 2135),\n",
       " ('direction', 2133),\n",
       " ('gives', 2123),\n",
       " ('hope', 2119),\n",
       " ('definitely', 2117),\n",
       " ('example', 2115),\n",
       " ('liked', 2109),\n",
       " ('certainly', 2098),\n",
       " ('cinema', 2097),\n",
       " ('writing', 2084),\n",
       " ('based', 2081),\n",
       " ('flick', 2074),\n",
       " ('totally', 2074),\n",
       " ('turn', 2070),\n",
       " ('guys', 2066),\n",
       " ('tries', 2064),\n",
       " ('beginning', 2063),\n",
       " ('sound', 2062),\n",
       " ('mr', 2060),\n",
       " ('several', 2056),\n",
       " ('friend', 2053),\n",
       " ('overall', 2046),\n",
       " ('fans', 2045),\n",
       " ('under', 2036),\n",
       " ('entertaining', 2033),\n",
       " ('becomes', 2031),\n",
       " ('quality', 2002),\n",
       " ('despite', 1999),\n",
       " ('lead', 1990),\n",
       " ('act', 1980),\n",
       " ('god', 1973),\n",
       " ('decent', 1972),\n",
       " ('hour', 1971),\n",
       " ('kill', 1961),\n",
       " ('car', 1957),\n",
       " ('perfect', 1954),\n",
       " ('drama', 1949),\n",
       " ('wonderful', 1944),\n",
       " ('b', 1937),\n",
       " ('crap', 1934),\n",
       " ('dark', 1932),\n",
       " ('child', 1927),\n",
       " ('behind', 1925),\n",
       " ('throughout', 1924),\n",
       " ('close', 1921),\n",
       " ('blood', 1918),\n",
       " ('final', 1915),\n",
       " ('hand', 1913),\n",
       " ('wants', 1905),\n",
       " ('son', 1903),\n",
       " ('thinking', 1899),\n",
       " ('starts', 1895),\n",
       " ('obviously', 1893),\n",
       " ('lives', 1892),\n",
       " ('run', 1886),\n",
       " ('kid', 1886),\n",
       " ('humor', 1886),\n",
       " ('etc', 1873),\n",
       " ('girls', 1873),\n",
       " ('except', 1863),\n",
       " ('michael', 1861),\n",
       " ('stuff', 1847),\n",
       " ('gave', 1845),\n",
       " ('art', 1844),\n",
       " ('days', 1840),\n",
       " ('history', 1840),\n",
       " ('game', 1834),\n",
       " ('side', 1833),\n",
       " ('turns', 1828),\n",
       " ('viewer', 1825),\n",
       " ('town', 1818),\n",
       " ('myself', 1810),\n",
       " ('actress', 1807),\n",
       " ('self', 1800),\n",
       " ('gore', 1800),\n",
       " ('annoying', 1793),\n",
       " ('eyes', 1793),\n",
       " ('able', 1792),\n",
       " ('fine', 1791),\n",
       " ('slow', 1789),\n",
       " ('attempt', 1785),\n",
       " ('writer', 1782),\n",
       " ('past', 1782),\n",
       " ('killed', 1778),\n",
       " ('expect', 1772),\n",
       " ('directed', 1772),\n",
       " ('save', 1769),\n",
       " ('loved', 1769),\n",
       " ('genre', 1767),\n",
       " ('themselves', 1760),\n",
       " ('lack', 1756),\n",
       " ('anyway', 1755),\n",
       " ('ridiculous', 1755),\n",
       " ('wouldn', 1747),\n",
       " ('soon', 1744),\n",
       " ('parts', 1737),\n",
       " ('ok', 1734),\n",
       " ('please', 1733),\n",
       " ('obvious', 1726),\n",
       " ('happens', 1720),\n",
       " ('none', 1720),\n",
       " ('fight', 1715),\n",
       " ('works', 1710),\n",
       " ('cannot', 1707),\n",
       " ('daughter', 1704),\n",
       " ('stop', 1702),\n",
       " ('heart', 1697),\n",
       " ('voice', 1697),\n",
       " ('says', 1694),\n",
       " ('late', 1692),\n",
       " ('sometimes', 1690),\n",
       " ('wonder', 1690),\n",
       " ('seriously', 1685),\n",
       " ('hell', 1682),\n",
       " ('looked', 1680),\n",
       " ('complete', 1674),\n",
       " ('heard', 1672),\n",
       " ('type', 1672),\n",
       " ('feeling', 1671),\n",
       " ('happened', 1668),\n",
       " ('cut', 1665),\n",
       " ('stories', 1664),\n",
       " ('matter', 1656),\n",
       " ('leave', 1653),\n",
       " ('violence', 1653),\n",
       " ('involved', 1646),\n",
       " ('took', 1631),\n",
       " ('extremely', 1631),\n",
       " ('happen', 1617),\n",
       " ('police', 1615),\n",
       " ('enjoyed', 1613),\n",
       " ('moment', 1612),\n",
       " ('alone', 1610),\n",
       " ('scary', 1607),\n",
       " ('hero', 1605),\n",
       " ('city', 1602),\n",
       " ('group', 1602),\n",
       " ('interest', 1594),\n",
       " ('jokes', 1587),\n",
       " ('cheap', 1583),\n",
       " ('amazing', 1582),\n",
       " ('particularly', 1576),\n",
       " ('saying', 1567),\n",
       " ('brother', 1566),\n",
       " ('running', 1563),\n",
       " ('coming', 1563),\n",
       " ('apparently', 1558),\n",
       " ('hours', 1557),\n",
       " ('hit', 1555),\n",
       " ('today', 1554),\n",
       " ('possible', 1554),\n",
       " ('yourself', 1551),\n",
       " ('age', 1541),\n",
       " ('body', 1536),\n",
       " ('known', 1533),\n",
       " ('roles', 1533),\n",
       " ('told', 1523),\n",
       " ('talking', 1521),\n",
       " ('chance', 1517),\n",
       " ('exactly', 1515),\n",
       " ('living', 1514),\n",
       " ('usually', 1510),\n",
       " ('started', 1508),\n",
       " ('shots', 1507),\n",
       " ('favorite', 1502),\n",
       " ('sad', 1495),\n",
       " ('dull', 1493),\n",
       " ('ends', 1493),\n",
       " ('call', 1492),\n",
       " ('silly', 1490),\n",
       " ('serious', 1490),\n",
       " ('female', 1489),\n",
       " ('disappointed', 1486),\n",
       " ('word', 1483),\n",
       " ('predictable', 1482),\n",
       " ('opening', 1480),\n",
       " ('murder', 1480),\n",
       " ('husband', 1480),\n",
       " ('basically', 1478),\n",
       " ('including', 1477),\n",
       " ('taken', 1477),\n",
       " ('experience', 1476),\n",
       " ('james', 1471),\n",
       " ('rating', 1471),\n",
       " ('middle', 1469),\n",
       " ('huge', 1468),\n",
       " ('brilliant', 1466),\n",
       " ('single', 1464),\n",
       " ('five', 1463),\n",
       " ('career', 1462),\n",
       " ('cool', 1461),\n",
       " ('ago', 1457),\n",
       " ('across', 1453),\n",
       " ('level', 1452),\n",
       " ('talent', 1446),\n",
       " ('turned', 1443),\n",
       " ('number', 1440),\n",
       " ('score', 1440),\n",
       " ('non', 1429),\n",
       " ('strong', 1428),\n",
       " ('english', 1428),\n",
       " ('king', 1427),\n",
       " ('aren', 1426),\n",
       " ('highly', 1425),\n",
       " ('shown', 1425),\n",
       " ('mostly', 1422),\n",
       " ('earth', 1419),\n",
       " ('taking', 1419),\n",
       " ('avoid', 1417),\n",
       " ('song', 1417),\n",
       " ('wish', 1415),\n",
       " ('major', 1414),\n",
       " ('order', 1411),\n",
       " ('bunch', 1403),\n",
       " ('novel', 1401),\n",
       " ('room', 1400),\n",
       " ('david', 1395),\n",
       " ('whose', 1394),\n",
       " ('lame', 1394),\n",
       " ('cinematography', 1391),\n",
       " ('usual', 1391),\n",
       " ('clearly', 1391),\n",
       " ('ones', 1389),\n",
       " ('released', 1386),\n",
       " ('review', 1385),\n",
       " ('opinion', 1383),\n",
       " ('fast', 1382),\n",
       " ('power', 1378),\n",
       " ('somewhat', 1377),\n",
       " ('reality', 1369),\n",
       " ('strange', 1367),\n",
       " ('straight', 1367),\n",
       " ('change', 1364),\n",
       " ('musical', 1359),\n",
       " ('light', 1358),\n",
       " ('poorly', 1358),\n",
       " ('beyond', 1357),\n",
       " ('view', 1355),\n",
       " ('simple', 1350),\n",
       " ('sequel', 1340),\n",
       " ('four', 1340),\n",
       " ('hilarious', 1339),\n",
       " ('sorry', 1336),\n",
       " ('documentary', 1335),\n",
       " ('knew', 1334),\n",
       " ('robert', 1333),\n",
       " ('words', 1333),\n",
       " ('falls', 1332),\n",
       " ('happy', 1331),\n",
       " ('due', 1330),\n",
       " ('effort', 1325),\n",
       " ('country', 1316),\n",
       " ('problems', 1311),\n",
       " ('easily', 1310),\n",
       " ('talk', 1309),\n",
       " ('knows', 1308),\n",
       " ('finds', 1305),\n",
       " ('local', 1304),\n",
       " ('theater', 1303),\n",
       " ('class', 1303),\n",
       " ('important', 1302),\n",
       " ('attention', 1301),\n",
       " ('appears', 1296),\n",
       " ('weak', 1295),\n",
       " ('modern', 1289),\n",
       " ('television', 1289),\n",
       " ('mention', 1289),\n",
       " ('tried', 1288),\n",
       " ('songs', 1286),\n",
       " ('entertainment', 1281),\n",
       " ('comic', 1281),\n",
       " ('ten', 1278),\n",
       " ('bring', 1278),\n",
       " ('thriller', 1275),\n",
       " ('relationship', 1275),\n",
       " ('minute', 1272),\n",
       " ('events', 1270),\n",
       " ('giving', 1270),\n",
       " ('storyline', 1269),\n",
       " ('editing', 1268),\n",
       " ('british', 1268),\n",
       " ('dialog', 1267),\n",
       " ('upon', 1265),\n",
       " ('whether', 1265),\n",
       " ('sequence', 1261),\n",
       " ('die', 1260),\n",
       " ('stay', 1259),\n",
       " ('add', 1253),\n",
       " ('zombie', 1250),\n",
       " ('rock', 1246),\n",
       " ('lee', 1245),\n",
       " ('o', 1244),\n",
       " ('near', 1242),\n",
       " ('points', 1242),\n",
       " ('lady', 1241),\n",
       " ('jack', 1240),\n",
       " ('needs', 1240),\n",
       " ('mystery', 1239),\n",
       " ('george', 1238),\n",
       " ('sets', 1237),\n",
       " ('using', 1234),\n",
       " ('hate', 1232),\n",
       " ('actual', 1231),\n",
       " ('miss', 1229),\n",
       " ('badly', 1228),\n",
       " ('feels', 1223),\n",
       " ('nearly', 1222),\n",
       " ('episodes', 1221),\n",
       " ('eye', 1213),\n",
       " ('similar', 1213),\n",
       " ('unless', 1211),\n",
       " ('within', 1209),\n",
       " ('tells', 1208),\n",
       " ('future', 1205),\n",
       " ('rent', 1203),\n",
       " ('okay', 1201),\n",
       " ('lots', 1199),\n",
       " ('material', 1198),\n",
       " ('somehow', 1198),\n",
       " ('premise', 1197),\n",
       " ('richard', 1197),\n",
       " ('paul', 1196),\n",
       " ('message', 1195),\n",
       " ('stand', 1194),\n",
       " ('above', 1194),\n",
       " ('whatever', 1192),\n",
       " ('supporting', 1188),\n",
       " ('mess', 1182),\n",
       " ('kept', 1180),\n",
       " ('haven', 1179),\n",
       " ('clear', 1178),\n",
       " ('comments', 1173),\n",
       " ('sister', 1173),\n",
       " ('red', 1162),\n",
       " ('named', 1161),\n",
       " ('sit', 1160),\n",
       " ('space', 1160),\n",
       " ('team', 1159),\n",
       " ('check', 1159),\n",
       " ('theme', 1153),\n",
       " ('imagine', 1151),\n",
       " ('fall', 1150),\n",
       " ('doubt', 1147),\n",
       " ('figure', 1147),\n",
       " ('general', 1145),\n",
       " ('feature', 1145),\n",
       " ('romantic', 1140),\n",
       " ('possibly', 1139),\n",
       " ('imdb', 1138),\n",
       " ('buy', 1136),\n",
       " ('herself', 1136),\n",
       " ('release', 1135),\n",
       " ('means', 1134),\n",
       " ('reviews', 1134),\n",
       " ('filmed', 1134),\n",
       " ('elements', 1133),\n",
       " ('killing', 1131),\n",
       " ('gone', 1129),\n",
       " ('average', 1128),\n",
       " ('follow', 1126),\n",
       " ('write', 1125),\n",
       " ('working', 1125),\n",
       " ('decided', 1124),\n",
       " ('showing', 1123),\n",
       " ('typical', 1121),\n",
       " ('wait', 1120),\n",
       " ('viewers', 1119),\n",
       " ('tom', 1116),\n",
       " ('surprised', 1113),\n",
       " ('ways', 1112),\n",
       " ('animation', 1112),\n",
       " ('enjoyable', 1111),\n",
       " ('moving', 1108),\n",
       " ('joke', 1108),\n",
       " ('york', 1107),\n",
       " ('suspense', 1104),\n",
       " ('monster', 1103),\n",
       " ('hear', 1102),\n",
       " ('third', 1099),\n",
       " ('move', 1098),\n",
       " ('expected', 1096),\n",
       " ('dumb', 1096),\n",
       " ('period', 1094),\n",
       " ('oscar', 1094),\n",
       " ('begins', 1094),\n",
       " ('free', 1090),\n",
       " ('nor', 1088),\n",
       " ('fails', 1087),\n",
       " ('peter', 1084),\n",
       " ('certain', 1082),\n",
       " ('writers', 1082),\n",
       " ('leads', 1081),\n",
       " ('otherwise', 1079),\n",
       " ('form', 1078),\n",
       " ('credits', 1077),\n",
       " ('forget', 1076),\n",
       " ('among', 1076),\n",
       " ('soundtrack', 1076),\n",
       " ('needed', 1075),\n",
       " ('easy', 1073),\n",
       " ('parents', 1073),\n",
       " ('french', 1073),\n",
       " ('sequences', 1071),\n",
       " ('shame', 1069),\n",
       " ('total', 1069),\n",
       " ('sexual', 1066),\n",
       " ('famous', 1059),\n",
       " ('begin', 1058),\n",
       " ('hot', 1056),\n",
       " ('reading', 1054),\n",
       " ('th', 1052),\n",
       " ('disney', 1051),\n",
       " ('eventually', 1047),\n",
       " ('dr', 1047),\n",
       " ('screenplay', 1045),\n",
       " ('crime', 1044),\n",
       " ('question', 1043),\n",
       " ('wasted', 1043),\n",
       " ('learn', 1042),\n",
       " ('cheesy', 1040),\n",
       " ('forced', 1040),\n",
       " ('tale', 1038),\n",
       " ('note', 1035),\n",
       " ('baby', 1034),\n",
       " ('america', 1033),\n",
       " ('subject', 1032),\n",
       " ('development', 1032),\n",
       " ('viewing', 1032),\n",
       " ('weird', 1031),\n",
       " ('footage', 1030),\n",
       " ('ask', 1029),\n",
       " ('dance', 1025),\n",
       " ('surprise', 1025),\n",
       " ('male', 1023),\n",
       " ('indeed', 1023),\n",
       " ('laughs', 1022),\n",
       " ('forward', 1022),\n",
       " ('particular', 1022),\n",
       " ('nudity', 1021),\n",
       " ('deal', 1018),\n",
       " ('sounds', 1018),\n",
       " ('directing', 1016),\n",
       " ('brought', 1015),\n",
       " ('japanese', 1015),\n",
       " ('de', 1014),\n",
       " ('dog', 1014),\n",
       " ('directors', 1011),\n",
       " ('stage', 1009),\n",
       " ('comment', 1006),\n",
       " ('street', 1005),\n",
       " ('box', 1003),\n",
       " ('truth', 1002),\n",
       " ('difficult', 1001),\n",
       " ('crazy', 999),\n",
       " ('incredibly', 996),\n",
       " ('season', 996),\n",
       " ('potential', 996),\n",
       " ('flat', 995),\n",
       " ('open', 995),\n",
       " ('joe', 992),\n",
       " ('realistic', 991),\n",
       " ('leaves', 991),\n",
       " ('girlfriend', 990),\n",
       " ('hardly', 989),\n",
       " ('cop', 987),\n",
       " ('acted', 986),\n",
       " ('gay', 985),\n",
       " ('result', 985),\n",
       " ('became', 984),\n",
       " ('realize', 984),\n",
       " ('fi', 983),\n",
       " ('plus', 981),\n",
       " ('plain', 979),\n",
       " ('atmosphere', 977),\n",
       " ('sci', 977),\n",
       " ('pay', 976),\n",
       " ('worked', 975),\n",
       " ('fire', 970),\n",
       " ('pointless', 970),\n",
       " ('christmas', 970),\n",
       " ('quickly', 968),\n",
       " ('air', 963),\n",
       " ('believable', 963),\n",
       " ('remake', 962),\n",
       " ('nature', 957),\n",
       " ('romance', 957),\n",
       " ('appear', 956),\n",
       " ('meant', 956),\n",
       " ('situation', 952),\n",
       " ('doctor', 951),\n",
       " ('hands', 950),\n",
       " ('apart', 947),\n",
       " ('dramatic', 946),\n",
       " ('creepy', 946),\n",
       " ('meet', 946),\n",
       " ('interested', 946),\n",
       " ('earlier', 944),\n",
       " ('previous', 943),\n",
       " ('twist', 942),\n",
       " ('fantastic', 941),\n",
       " ('greatest', 941),\n",
       " ('admit', 940),\n",
       " ('casting', 940),\n",
       " ('e', 939),\n",
       " ('effect', 939),\n",
       " ('ideas', 937),\n",
       " ('sadly', 937),\n",
       " ('attempts', 934),\n",
       " ('villain', 931),\n",
       " ('mark', 931),\n",
       " ('towards', 930),\n",
       " ('rate', 926),\n",
       " ('break', 926),\n",
       " ('spoilers', 926),\n",
       " ('zombies', 924),\n",
       " ('bored', 923),\n",
       " ('features', 923),\n",
       " ('whom', 920),\n",
       " ('older', 919),\n",
       " ('dream', 918),\n",
       " ('filmmakers', 914),\n",
       " ('fighting', 913),\n",
       " ('list', 912),\n",
       " ('missing', 909),\n",
       " ('create', 908),\n",
       " ('setting', 908),\n",
       " ('background', 906),\n",
       " ('front', 906),\n",
       " ('wrote', 905),\n",
       " ('telling', 904),\n",
       " ('ben', 903),\n",
       " ('meets', 902),\n",
       " ('expecting', 899),\n",
       " ('co', 897),\n",
       " ('leading', 896),\n",
       " ('society', 896),\n",
       " ('deep', 894),\n",
       " ('gun', 894),\n",
       " ('plenty', 893),\n",
       " ('secret', 893),\n",
       " ('outside', 893),\n",
       " ('bill', 892),\n",
       " ('spent', 892),\n",
       " ('keeps', 891),\n",
       " ('neither', 888),\n",
       " ('reasons', 887),\n",
       " ('fairly', 884),\n",
       " ('jane', 884),\n",
       " ('trash', 883),\n",
       " ('c', 881),\n",
       " ('talented', 878),\n",
       " ('return', 878),\n",
       " ('pathetic', 875),\n",
       " ('business', 873),\n",
       " ('boys', 872),\n",
       " ('cover', 871),\n",
       " ('fantasy', 870),\n",
       " ('emotional', 869),\n",
       " ('inside', 867),\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is just to show the most common words in the positive and negative sentences. However, there are a lot of unnecessary words like `the`, `a`, `was`, and so on. Can you find a way to show the relevant words and not these words? \n",
    "\n",
    "```\n",
    "Hint: Stop Words removal or normalizing each term.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell',\n",
       " 'high',\n",
       " 'is',\n",
       " 'a',\n",
       " 'cartoon',\n",
       " 'comedy',\n",
       " 'it',\n",
       " 'ran',\n",
       " 'at',\n",
       " 'the',\n",
       " 'same',\n",
       " 'time',\n",
       " 'as',\n",
       " 'some',\n",
       " 'other',\n",
       " 'programs',\n",
       " 'about',\n",
       " 'school',\n",
       " 'life',\n",
       " 'such',\n",
       " 'as',\n",
       " 'teachers',\n",
       " 'my',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'teaching',\n",
       " 'profession',\n",
       " 'lead',\n",
       " 'me']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21025,\n",
       " 308,\n",
       " 6,\n",
       " 3,\n",
       " 1050,\n",
       " 207,\n",
       " 8,\n",
       " 2138,\n",
       " 32,\n",
       " 1,\n",
       " 171,\n",
       " 57,\n",
       " 15,\n",
       " 49,\n",
       " 81,\n",
       " 5785,\n",
       " 44,\n",
       " 382,\n",
       " 110,\n",
       " 140,\n",
       " 15,\n",
       " 5194,\n",
       " 60,\n",
       " 154,\n",
       " 9,\n",
       " 1,\n",
       " 4975,\n",
       " 5852,\n",
       " 475,\n",
       " 71]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab_to_int[word] for word in words[:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21025"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_int['bromwell']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding\n",
    "\n",
    "We need one hot encoding for the labels. Think of a reason why we need one hot encoded labels for classes?\n",
    "\n",
    "## Task 3: Create one hot encoding for the labels. \n",
    "\n",
    "* Write the one hot encoding logic in the `one_hot` function.\n",
    "* Use 1 for positive label and 0 for negative label.\n",
    "* Save all the values in the `encoded_labels` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 for positive label and 0 for negative label\n",
    "def one_hot(labels):\n",
    "    pass\n",
    "encoded_labels = one_hot(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print the length of your label and uncomment next line only if the encoded_labels size is 25001.\n",
    "# If you dont get the intuition behind this step, print encoded_labels to see it.\n",
    "#encoded_labels = encoded_labels[:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_ints = []\n",
    "for review in reviews_split:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-length reviews: 1\n",
      "Maximum review length: 2514\n"
     ]
    }
   ],
   "source": [
    "# This step is to see if any review is empty and we remove it. Otherwise the input will be all zeroes.\n",
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews before removing outliers:  25001\n",
      "Number of reviews after removing outliers:  25000\n"
     ]
    }
   ],
   "source": [
    "print('Number of reviews before removing outliers: ', len(reviews_ints))\n",
    "\n",
    "## remove any reviews/labels with zero length from the reviews_ints list.\n",
    "\n",
    "# get indices of any reviews with length 0\n",
    "non_zero_idx = [ii for ii, review in enumerate(reviews_ints) if len(review) != 0]\n",
    "\n",
    "# remove 0-length reviews and their labels\n",
    "reviews_ints = [reviews_ints[ii] for ii in non_zero_idx]\n",
    "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
    "\n",
    "print('Number of reviews after removing outliers: ', len(reviews_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Padding the data\n",
    "\n",
    "> Define a function that returns an array `features` that contains the padded data, of a standard size, that we'll pass to the network. \n",
    "* The data should come from `review_ints`, since we want to feed integers to the network. \n",
    "* Each row should be `seq_length` elements long. \n",
    "* For reviews shorter than `seq_length` words, **left pad** with 0s. That is, if the review is `['best', 'movie', 'ever']`, `[117, 18, 128]` as integers, the row will look like `[0, 0, 0, ..., 0, 117, 18, 128]`. \n",
    "* For reviews longer than `seq_length`, use only the first `seq_length` words as the feature vector.\n",
    "\n",
    "As a small example, if the `seq_length=10` and an input review is: \n",
    "```\n",
    "[117, 18, 128]\n",
    "```\n",
    "The resultant, padded sequence should be: \n",
    "\n",
    "```\n",
    "[0, 0, 0, 0, 0, 0, 0, 117, 18, 128]\n",
    "```\n",
    "\n",
    "**Your final `features` array should be a 2D array, with as many rows as there are reviews, and as many columns as the specified `seq_length`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the logic for padding the data\n",
    "def pad_features(reviews_ints, seq_length):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [22382    42 46418    15   706 17139  3389    47    77    35]\n",
      " [ 4505   505    15     3  3342   162  8312  1652     6  4819]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [   54    10    14   116    60   798   552    71   364     5]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    1   330   578    34     3   162   748  2731     9   325]\n",
      " [    9    11 10171  5305  1946   689   444    22   280   673]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    1   307 10399  2069  1565  6202  6528  3288 17946 10628]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [   21   122  2069  1565   515  8181    88     6  1325  1182]\n",
      " [    1    20     6    76    40     6    58    81    95     5]\n",
      " [   54    10    84   329 26230 46427    63    10    14   614]\n",
      " [   11    20     6    30  1436 32317  3769   690 15100     6]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [   40    26   109 17952  1422     9     1   327     4   125]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [   10   499     1   307 10399    55    74     8    13    30]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# Verify if everything till now is correct. \n",
    "\n",
    "seq_length = 200\n",
    "\n",
    "features = pad_features(reviews_ints, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[:30,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything ready. It's time to split our dataset into `Train`, `Test` and `Validate`. \n",
    "\n",
    "Read more about the train-test-split here : https://cs230-stanford.github.io/train-dev-test-split.html\n",
    "\n",
    "## Task 5: Lets create train, test and val split in the ratio of 8:1:1.  \n",
    "\n",
    "Hint: Either use shuffle and slicing in Python or use train-test-val split in Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_frac = 0.8\n",
    "val_frac = 0.1\n",
    "test_frac = 0.1\n",
    "\n",
    "\n",
    "def train_test_val_split(features):\n",
    "    pass\n",
    "\n",
    "def train_test_val_labels(encoded_labels):\n",
    "    pass\n",
    "\n",
    "train_x, val_x, test_x = train_test_val_split(features)\n",
    "train_y, val_y, test_y = train_test_val_labels(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(20000, 200) \n",
      "Validation set: \t(2500, 200) \n",
      "Test set: \t\t(2500, 200)\n"
     ]
    }
   ],
   "source": [
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders and Batching\n",
    "\n",
    "After creating training, test, and validation data, we can create DataLoaders for this data by following two steps:\n",
    "1. Create a known format for accessing our data, using [TensorDataset](https://pytorch.org/docs/stable/data.html#) which takes in an input set of data and a target set of data with the same first dimension, and creates a dataset.\n",
    "2. Create DataLoaders and batch our training, validation, and test Tensor datasets.\n",
    "\n",
    "```\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "```\n",
    "\n",
    "This is an alternative to creating a generator function for batching our data into full batches.\n",
    "\n",
    "### Task 6: Create a generator function for the dataset. \n",
    "See the above link for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets for train, test and val\n",
    "train_data = \n",
    "valid_data = \n",
    "test_data = \n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50 \n",
    "\n",
    "# make sure to SHUFFLE your training data. Keep Shuffle=True.\n",
    "train_loader = \n",
    "valid_loader = \n",
    "test_loader = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain one batch of training data and label. \n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available.\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model \n",
    "\n",
    "Here we are creating a simple RNN in PyTorch and pass the output to the a Linear layer and Sigmoid at the end to get the probability score and prediction as POSITIVE or NEGATIVE. \n",
    "\n",
    "The network is very similar to the CNN network created in Exercise 2. \n",
    "\n",
    "More info available at: https://pytorch.org/docs/0.3.1/nn.html?highlight=rnn#torch.nn.RNN\n",
    "\n",
    "Read about the parameters that the RNN takes and see what will happen when `batch_first` is set as `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(vocab_size, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # RNN out layer\n",
    "        rnn_out, hidden = self.rnn(x, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        rnn_out = rnn_out.view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(rnn_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 7 : Know the shape\n",
    "\n",
    "Given a batch of 64 and input size as 1 and a sequence length of 200 to a RNN with 2 stacked layers and 512 hidden layers, find the shape of input data (x) and the hidden dimension (hidden) specified in the forward pass of the network. Note, the batch_first is kept to be True. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "hidden_dim = 256\n",
    "n_layers = 1\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 8: LSTM \n",
    "\n",
    "Before we start creating the LSTM, it is important to understand LSTM and to know why we prefer LSTM over a Vanilla RNN for this task. \n",
    "> Here are some good links to know about LSTM:\n",
    "* [Colah Blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "* [Understanding LSTM](http://blog.echen.me/2017/05/30/exploring-lstms/)\n",
    "* [RNN effectiveness](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "\n",
    "Now create a class named SentimentLSTM with `n_layers=2`, and rest all hyperparameters same as before. Also, create an embedding layer and feed the output of the embedding layer as input to the LSTM model. Dont forget to add a regularizer (dropout) layer after the LSTM layer with p=0.4 to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    The LSTM model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # define embedding, LSTM, dropout and Linear layers here\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the network\n",
    "\n",
    "Here, we'll instantiate the network. First up, defining the hyperparameters.\n",
    "\n",
    "* `vocab_size`: Size of our vocabulary or the range of values for our input, word tokens.\n",
    "* `output_size`: Size of our desired output; the number of class scores we want to output (pos/neg).\n",
    "* `embedding_dim`: Number of columns in the embedding lookup table; size of our embeddings.\n",
    "* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
    "* `n_layers`: Number of LSTM layers in the network. Typically between 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the model with these hyperparameters\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 300\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Loss Functions\n",
    "We are using `BCELoss (Binary Cross Entropy Loss)` since we have two output classes. \n",
    "\n",
    "Can Cross Entropy Loss be used instead of BCELoss? \n",
    "\n",
    "If no, why not? If yes, how?\n",
    "\n",
    "Is `NLLLoss()` and last layer as `LogSoftmax()` is same as using `CrossEntropyLoss()` with a Softmax final layer? Can you get the mathematical intuition behind it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training and Validation\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Once we are done with training and validating, we can improve training loss and validation loss by playing around with the hyperparameters. Can you find a better set of hyperparams? Play around with it. \n",
    "\n",
    "### Task 10: Prediction Function\n",
    "Now write a prediction function to predict the output for the test set created. Save the results in a CSV file with one column as the reviews and the prediction in the next column. Calculate the accuracy of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Question: Create an app using Flask\n",
    "\n",
    "> Extra bonus points if someone attempts this question:\n",
    "* Save the trained model checkpoints.\n",
    "* Create a Flask app and load the model. A similar work in the field of CNN has been done here : https://github.com/kumar-shridhar/Business-Card-Detector (Check `app.py`)\n",
    "* You can use hosting services like Heroku and/or with Docker to host your app and show it to everyone. \n",
    "Example here: https://github.com/selimrbd/sentiment_analysis/blob/master/Dockerfile\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
